import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import cross_val_score,learning_curve, train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import make_pipeline
from xgboost import XGBClassifier
from sklearn.metrics import auc,confusion_matrix, roc_curve, classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler
from scipy import stats
from scipy.stats import chi2_contingency, f_oneway
from sklearn.compose import make_column_transformer, ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder
from sklearn.datasets import make_classification
from sklearn.metrics import RocCurveDisplay
from sklearn.tree import export_graphviz
import eli5
from eli5.sklearn import PermutationImportance
from subprocess import call
from IPython.display import Image

import warnings
warnings.filterwarnings('ignore')

def ignore_warn(*args, **kwargs):
    pass
warnings.warn = ignore_warn 

pd.set_option("display.float_format", lambda x: "{:.3f}".format(x)) #Limiting floats output to 3 decimal points
pd.set_option("display.max_columns", None)
data = pd.read_csv("/kaggle/input/heart-disease-uci/heart.csv")
data.head()
data.shape
data.info()
data.describe(include="all")
data.isnull().sum()
data.hist(figsize=(10,10))
plt.show()
sns.countplot(data.target, palette="bwr")
plt.show()
data.target.value_counts(normalize=True)
continuous_cols = [col for col in data.columns if data[col].nunique()>15]
print(continuous_cols)
matrix = data[continuous_cols].corr()
mask = np.triu(np.ones_like(matrix, dtype=bool))
sns.heatmap(matrix, mask=mask, annot=True)
fig, axes = plt.subplots(nrows=2,ncols=3, figsize=(12,12))
sns.boxplot(y=data.age, ax=axes[0, 0])
sns.boxplot(y=data.trestbps, ax=axes[0, 1])
sns.boxplot(y=data.chol, ax=axes[0, 2])
sns.boxplot(y=data.thalach,ax=axes[1, 0])
sns.boxplot(y=data.oldpeak,ax=axes[1, 1])
plt.show()
outliers = []
def percentile_outliers(col):
    q1 = np.percentile(col, 1)
    q3 = np.percentile(col, 99)
    IQR = q3-q1
    for i in col:
        if i > q3 or i < q1:
            outliers.append(i)
    print("Outliers:",outliers)
    utliers = []
chol_out = percentile_outliers(data['chol'].sort_values())
print(chol_out)
data.drop((data[data.chol > 400].index) | (data[data.chol < 141].index), inplace=True)
outliers = []
thalach_out = percentile_outliers(data['thalach'].sort_values())
print(thalach_out)
data.drop((data[data.thalach > 191].index) | (data[data.thalach < 96].index), inplace=True)
outliers = []
trestbps_out = percentile_outliers(data['trestbps'].sort_values())
print(trestbps_out)
data.drop((data[data.trestbps > 191].index) | (data[data.trestbps < 95].index), inplace=True)
def anova_test(feature, target):
    CategoryGroupLists=data.groupby(feature)[target].apply(list)
    AnovaResults = f_oneway(*CategoryGroupLists)
    return round(AnovaResults[1],4)

continuous_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']
print("Age and target: P value is {}".format(anova_test("age", "target")))
print("trestbps and target: P value is {}".format(anova_test("trestbps", "target")))
print("chol and target: P value is {}".format(anova_test("chol", "target")))
print("thalach and target: P value is {}".format(anova_test("thalach", "target")))
print("oldpeak and target: P value is {}".format(anova_test("oldpeak", "target")))
plt.figure(figsize=(15, 15))

for i, col in enumerate(continuous_cols, 1):
    plt.subplot(3, 2, i)
    data[data["target"] == 0][col].hist(bins=35, color='green', label='Heart Disease = NO', alpha=0.6)
    data[data["target"] == 1][col].hist(bins=35, color='red', label='Heart Disease = YES', alpha=0.6)
    plt.legend()
    plt.title('{}, subplot: {}'.format(i, col))
    plt.xlabel(col)
    cat_cols = [col for col in data.columns if data[col].nunique()<=15] #categorical columns
print(cat_cols)
cat_cols.remove("target") # dropped the target column
print(cat_cols)
def chitest(indepentVal, dependentVal):
    # Cross tabulation between two variables
    Crosstable = pd.crosstab(index=indepentVal,columns=dependentVal)

    # Performing Chi-sq test
    ChiSqResult = chi2_contingency(Crosstable) #chi2_contingency module from scipy.stats

    # P-Value is the Probability of H0 being True
    # H0 is that two variable are not related
    # If P-Value&gt;0.05 then only we Accept the assumption(H0)
    return round(ChiSqResult[1],4)
    fig, axes = plt.subplots(nrows=2,ncols=4, figsize=(12,8))
pd.crosstab(data.ca, data.target).plot(kind="bar",ax=axes[0, 0])
pd.crosstab(data.cp, data.target).plot(kind="bar",ax=axes[0, 1])
pd.crosstab(data.exang, data.target).plot(kind="bar",ax=axes[0, 2])
pd.crosstab(data.restecg, data.target).plot(kind="bar",ax=axes[0, 3])
pd.crosstab(data.sex, data.target).plot(kind="bar",ax=axes[1, 0])
pd.crosstab(data.slope, data.target).plot(kind="bar",ax=axes[1,1])
pd.crosstab(data.thal, data.target).plot(kind="bar",ax=axes[1, 2])
plt.show()
ohe_col = []
for col in data.columns:
    if data[col].nunique() < 15:
        ohe_col.append(col)
        print("{}{}".format(col, data[col].unique()))
ohe_col.remove("target")
X = data.drop("target", axis=1)
y = data.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

ct = make_column_transformer((OneHotEncoder(handle_unknown='ignore'),ohe_col), remainder='passthrough')
sc = StandardScaler()

print(X_train.shape, X_test.shape)
accuracies = {}
def evaluation(model_name, model, X_train, y_train, X_test, y_test):
    y_train_preds = model.predict(X_train)
    y_test_preds = model.predict(X_test)
    acc_train = accuracy_score(y_train, y_train_preds),
    acc_test = accuracy_score(y_test, y_test_preds),
    accuracies[model_name] = [acc_train,acc_test]
    return accuracies
    def print_score(model, X_train, y_train, X_test, y_test):
    y_train_preds = model.predict(X_train)
    y_test_preds = model.predict(X_test)
    train_t = pd.DataFrame(classification_report(y_train,y_train_preds, output_dict=True))
    test_t = pd.DataFrame(classification_report(y_test,y_test_preds, output_dict=True))
    return pd.concat([train_t, test_t], keys=['Trai_score', 'Test_score']) 
    model = DecisionTreeClassifier(random_state=42) 
pipe = make_pipeline(ct, model)
pipe.get_params().keys()
params = {'decisiontreeclassifier__splitter': ["best", "random"],
          'decisiontreeclassifier__max_depth': np.arange(1,10,1),
          'decisiontreeclassifier__min_samples_leaf': np.arange(1,5,1),
          'decisiontreeclassifier__min_samples_split': np.arange(2,5,1)
         }
cv_dt = GridSearchCV(pipe, param_grid=params, scoring="accuracy", n_jobs=-1)
cv_dt.fit(X_train, y_train)
preds_dt = cv_dt.predict(X_test)
print(cv_dt.best_params_, cv_dt.best_score_)
print(cv_dt.score(X_test, y_test))
from sklearn import tree
import graphviz
clf = DecisionTreeClassifier(max_depth=7, min_samples_leaf=2, min_samples_split=2, splitter="random")
clf.fit(X_train, y_train)
dot_data = tree.export_graphviz(clf, out_file=None, 
                                feature_names=X_train.columns, 
                                filled=True, rounded=True,  
                                special_characters=True)  

graph = graphviz.Source(dot_data) 
graph.render("Heart Disease") 
model = RandomForestClassifier(random_state=42) 
pipe = make_pipeline(ct, model)
pipe.get_params().keys()
params = {'randomforestclassifier__n_estimators': np.arange(10,50,10),
         'randomforestclassifier__max_depth': np.arange(1,8,2)
         }
cv_rf = GridSearchCV(pipe, param_grid=params, scoring="accuracy", n_jobs=-1, cv=5)
cv_rf.fit(X_train, y_train)
preds_rf = cv_rf.predict(X_test)
print(cv_rf.best_params_, cv_rf.best_score_)
print(cv_rf.score(X_test, y_test))
model = LogisticRegression(solver='liblinear', random_state=42) 
pipe = make_pipeline(ct, sc, model)
#pipe.get_params().keys()
params = {'logisticregression__penalty': ['l1','l2'], 'logisticregression__C': np.arange(0.1,1,0.1)}
cv_lr = GridSearchCV(pipe, param_grid=params, scoring="accuracy", n_jobs=-1)
cv_lr.fit(X_train, y_train)
preds_lr = cv_lr.predict(X_test)
print(cv_lr.best_params_, cv_lr.best_score_)
print(cv_lr.score(X_test, y_test))
model = SVC(random_state=42) 
pipe = make_pipeline(ct, sc, model)
pipe.get_params().keys()
params = {'svc__kernel': ['linear', 'rbf'], 'svc__C': np.arange(0.5,1,0.1), 'svc__gamma': np.arange(0.01,0.05,0.01)}
cv_svm = GridSearchCV(pipe, param_grid=params, scoring="accuracy", n_jobs=-1)
cv_svm.fit(X_train, y_train)
preds_svm = cv_svm.predict(X_test)
print(cv_svm.best_params_, cv_svm.best_score_)
print(cv_svm.score(X_test, y_test))
model = KNeighborsClassifier() 
pipe = make_pipeline(ct, sc, model)
pipe.get_params().keys()
params = {'kneighborsclassifier__n_neighbors': np.arange(5,10,1), "kneighborsclassifier__weights": ['uniform', 'distance']}
cv_knn = GridSearchCV(pipe, param_grid=params, scoring="accuracy", n_jobs=-1)
cv_knn.fit(X_train, y_train)
preds_knn = cv_knn.predict(X_test)
print(cv_knn.best_params_, cv_knn.best_score_)
print(cv_knn.score(X_test, y_test))
evaluation("Logistic Model", cv_lr, X_train, y_train, X_test, y_test)
evaluation("SVM Model", cv_svm, X_train, y_train, X_test, y_test)
evaluation("Knn Model", cv_knn, X_train, y_train, X_test, y_test)
evaluation("Decision Tree Model", cv_dt, X_train, y_train, X_test, y_test)
evaluation("Random Forest Model", cv_rf, X_train, y_train, X_test, y_test)
evaluation("XGBoost Model", cv_xg, X_train, y_train, X_test, y_test)

accuracies = pd.DataFrame.from_dict(accuracies, orient="index", columns=['Train_acc', 'Test_acc'])
accuracies
for col in cat_cols:
    data[col] = data[col].astype("object")
    
X = data.drop("target", axis=1)
X = pd.get_dummies(X, drop_first=True)
y = data.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(X_train.shape, X_test.shape)
model = RandomForestClassifier(max_depth=5, n_estimators=10, random_state=42)
model.fit(X_train, y_train)
# Extract single tree
estimator = model.estimators_[5]
feature_names = [i for i in X_train.columns]

y_train_str = y_train.astype('str')
y_train_str[y_train_str == '0'] = 'no disease'
y_train_str[y_train_str == '1'] = 'disease'
#type(y_train_str.values)
target_names = y_train_str.values
from sklearn.tree import export_graphviz
# Export as dot file
export_graphviz(estimator, out_file='tree.dot', 
                feature_names = feature_names,
                class_names = target_names,
                rounded = True, proportion = False, 
                precision = 2, filled = True)

# Convert to png using system command (requires Graphviz)
from subprocess import call
call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])

# Display in jupyter notebook
from IPython.display import Image
Image(filename = 'tree.png')
from pdpbox import pdp, info_plots #for partial plots
cols = X.columns.tolist()


for i, col in enumerate(cols, 1):
    pdp_dist_rf = pdp.pdp_isolate(model=model, dataset=X_test, model_features=cols, feature=col)
    #pdp_dist_dt = pdp.pdp_isolate(model=decision_tree_model, dataset=X_test, model_features=cols, feature=col)
    pdp.pdp_plot(pdp_dist_rf, col, figsize=(5,5))
    plt.title('Random Forest subplot {}: {} vs target'.format(i, col))
    #pdp.pdp_plot(pdp_dist_dt, col, figsize=(5,5))
    #plt.title('Decision Tree subplot {}: {} vs target'.format(i, col))
    plt.show()
    import shap #for SHAP values
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)

shap.summary_plot(shap_values[1], X_test, plot_type="bar")
shap.summary_plot(shap_values[1], X_test)
def heart_disease_risk_factors(model, patient):
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(patient)
    shap.initjs()
    return shap.force_plot(explainer.expected_value[1], shap_values[1], patient)

data_for_prediction = X_test.iloc[1,:].astype(float)
heart_disease_risk_factors(model, data_for_prediction)
y_pred = model.predict(X_test)

# check performance with confusion matrix
cm = confusion_matrix(y_test, y_pred)
total = np.sum(cm)
sensitivity = cm[0,0]/(cm[0,0] + cm[1,0])
specificity = cm[1,1]/(cm[0,1] + cm[1,1])
print('Sensitivity : {:.2f}, Specificity: {:.2f}'.format(sensitivity,specificity))
y_pred_prob = model.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob, pos_label=1)

auc_score = auc(fpr, tpr)
print('Area under the curve : {:.4f}'.format(auc_score))

# plot Receiver operating characteristic curve
plt.figure(figsize=(7,7))
plt.plot(
    fpr,
    tpr,
    color="darkorange",
    lw=2,
    label="ROC curve (area = %0.2f)" % auc_score,
)
plt.plot([0, 1], [0, 1], color="navy", lw=2, linestyle="--")
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate (1-Specificity)")
plt.ylabel("True Positive Rate")
plt.title("ROC curve of heart disease classifier")
plt.legend(loc="lower right")
#plt.grid(True)
plt.show()
for col in cat_cols:
    data[col] = data[col].astype("object")
drop_cols = ["sex", "fbs", "age", "trestbps", "target"]
X = data.drop(drop_cols, axis=1)
y = data.target
X = pd.get_dummies(X, drop_first=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(random_state=42, n_estimators=10, max_depth=5) 
model.fit(X_train, y_train)
print(model.score(X_test, y_test))
print_score(model, X_train, y_train, X_test, y_test)
y_train_str = y_train.astype('str')
y_train_str[y_train_str == '0'] = 'no disease'
y_train_str[y_train_str == '1'] = 'disease'
#type(y_train_str.values)
target_names = y_train_str.values



from sklearn.tree import export_graphviz
# Export as dot file
export_graphviz(estimator, out_file='tree.dot', 
                feature_names = feature_names,
                class_names = target_names,
                rounded = True, proportion = False, 
                precision = 2, filled = True)

# Convert to png using system command (requires Graphviz)
from subprocess import call
call(['dot', '-Tpng', 'tree.dot', '-o', 'tree2.png', '-Gdpi=600'])

# Display in jupyter notebook
from IPython.display import Image
Image(filename = 'tree2.png')

    
